{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Behavior-Guided Reinforcement Learning\n",
    "\n",
    "This is a demo for the paper Behavior-Guided Reinforcement Learning. In this notebook we introduce our mechanism for calculating the Wasserstein Distance (WD), and apply it to Evolution Strategies (ES) to solve a simple yet deceptively tricky RL environment with our Behavior-Guided Evolution Strategies (BGES) algorithm. \n",
    "\n",
    "This is purely illustrative, for reader's convenience, since we introduce quite a few technical concepts and understand it may not be straightforward to grasp.\n",
    "\n",
    "The code we used for the experiments in the paper was internal and distributed, but this code is designed to run on a single machine in very little time, so we hope that reduces the barrier for people to reproduce/evaluate our method, and hopefully have some fun!\n",
    "\n",
    "But first, some preliminaries..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import gym\n",
    "import simpleenvs # a custom mujoco env we built for this work, more details in the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now here's the class which computes the Behavioral Test Functions (denoted beta_1 and beta_2). We use random features from [1] which means we do not need to compute the kernel matrix exactly (please see Section 4.2 for a detailed explanation). \n",
    "\n",
    "The loss function here is what we use to actually calculate the WD using the latest beta_1 and beta_2. You will see that during the optimization, we first update the behavioral test functions using the new data, then we apply these to evaluate the policies and compute their WDs. But that will come a little later!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class random_wassdist(object):\n",
    "    def __init__(self, params):\n",
    "        self.sigma = 1.0\n",
    "        self.gamma = 1.0\n",
    "        self.T = 10\n",
    "        self.n = 1 # num of data points per batch to update kernel function\n",
    "        self.xdim = params['dim']\n",
    "        self.alpha = 5e-2\n",
    "        self.D = params['rf_dim'] # random feature dimension\n",
    "        self.omega = np.random.randn(self.D, self.xdim) * 1.0 / self.sigma\n",
    "        self.bias = np.random.rand(self.D, 1) * 2 * np.pi\n",
    "        self.t = 0\n",
    "\n",
    "    def get_random_feature(self, x):\n",
    "        return np.cos(np.dot(self.omega, x) + self.bias) * np.sqrt(2. / self.D)\n",
    "\n",
    "    def update(self, X, Y, params):\n",
    "        # sample and update behavioral test functions using single_update\n",
    "        for _ in range(params['w_iter']):\n",
    "            x = np.array(X[int(np.random.uniform() * len(X))])\n",
    "            y = np.array(Y[int(np.random.uniform() * len(X))])\n",
    "            self.single_update(x, y)\n",
    "\n",
    "    def single_update(self, x, y):\n",
    "        if self.t == 0:\n",
    "            # initialize the functions\n",
    "            x = np.expand_dims(x, axis=1)\n",
    "            y = np.expand_dims(y, axis=1)\n",
    "            self.beta_1 = self.get_random_feature(x).flatten()\n",
    "            self.beta_2 = self.get_random_feature(y).flatten()\n",
    "        else:   \n",
    "            x = np.expand_dims(x, axis=1)\n",
    "            y = np.expand_dims(y, axis=1)\n",
    "            \n",
    "            # map to random feature space\n",
    "            zx = self.get_random_feature(x)\n",
    "            zy = self.get_random_feature(y)\n",
    "\n",
    "            C = np.sum((x-y)**2, axis=0)\n",
    "            coeff = np.exp((np.dot(self.beta_1, zx) - np.dot(self.beta_2, zy) - C) / self.gamma)\n",
    "            weight = (1 - coeff)\n",
    "            weight = np.expand_dims(weight, axis=0)\n",
    "            \n",
    "            # update the functions\n",
    "            self.beta_1 += self.alpha * np.mean(weight * zx, axis=1)\n",
    "            self.beta_2 += self.alpha * np.mean(weight * zy, axis=1)\n",
    "        self.t += 1\n",
    "\n",
    "    def wd(self, x, y):\n",
    "        x = np.expand_dims(x, axis=1)\n",
    "        y = np.expand_dims(y, axis=1)\n",
    "        \n",
    "        zx = self.get_random_feature(x)\n",
    "        zy = self.get_random_feature(y)\n",
    "        wd = np.dot(self.beta_1, zx) - np.dot(self.beta_2, zy) + (1/self.gamma) * np.exp((np.dot(self.beta_1, zx) - np.dot(self.beta_2, zy) - np.sum((x-y)**2))/self.gamma)\n",
    "        return wd\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to start talking about reinforcement learning. First up, here's the policy. It is a Toeplitz policy from [2]. This is a compact representation often used for ES methods to reduce the number of parameters. In this case we are running this on a single machine, so it is an effective way to make the code more efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import toeplitz\n",
    "\n",
    "class ToeplitzPolicy(object):\n",
    "    \n",
    "    def __init__(self, policy_params):\n",
    "        \n",
    "        self.init_seed = policy_params['seed']\n",
    "        self.ob_dim = policy_params['ob_dim']\n",
    "        self.h_dim = policy_params['h_dim']\n",
    "        self.ac_dim = policy_params['ac_dim']\n",
    "        \n",
    "        self.w1 = self.weight_init(self.ob_dim + self.h_dim -1, policy_params['zeros'])\n",
    "        self.w2 = self.weight_init(self.h_dim * 2 - 1, policy_params['zeros'])\n",
    "        self.w3 = self.weight_init(self.ac_dim + self.h_dim - 1, policy_params['zeros'])\n",
    "        \n",
    "        self.W1 = self.build_layer(self.h_dim, self.ob_dim, self.w1)\n",
    "        self.W2 = self.build_layer(self.h_dim, self.h_dim, self.w2)\n",
    "        self.W3 = self.build_layer(self.ac_dim, self.h_dim, self.w3)\n",
    "        \n",
    "        self.b1 = self.weight_init(self.h_dim, policy_params['zeros'])\n",
    "        self.b2 = self.weight_init(self.h_dim, policy_params['zeros'])\n",
    "    \n",
    "        self.params = np.concatenate([self.w1, self.b1, self.w2, self.b2, self.w3])\n",
    "        self.N = len(self.params)\n",
    "    \n",
    "    def weight_init(self, d, zeros):\n",
    "        if zeros:\n",
    "            w = np.zeros(d)\n",
    "        else:\n",
    "            np.random.seed(self.init_seed)\n",
    "            w = np.random.rand(d) / np.sqrt(d)\n",
    "        return(w)\n",
    "    \n",
    "    def build_layer(self, d1, d2, v):\n",
    "        # len v = d1 + d2 - 1\n",
    "        col = v[:d1]\n",
    "        row = v[(d1-1):]\n",
    "        \n",
    "        W = toeplitz(col, row)\n",
    "        return(W)\n",
    "    \n",
    "    def update(self, vec):\n",
    "        \n",
    "        self.params += vec\n",
    "        \n",
    "        self.w1 += vec[:len(self.w1)]\n",
    "        vec = vec[len(self.w1):]\n",
    "        self.b1 += vec[:len(self.b1)]\n",
    "        vec = vec[len(self.b1):]\n",
    "        self.w2 += vec[:len(self.w2)]\n",
    "        vec = vec[len(self.w2):]\n",
    "        self.b2 += vec[:len(self.b2)]\n",
    "        vec = vec[len(self.b2):]\n",
    "        self.w3 += vec\n",
    "        \n",
    "        self.W1 = self.build_layer(self.h_dim, self.ob_dim, self.w1)\n",
    "        self.W2 = self.build_layer(self.h_dim, self.h_dim, self.w2)\n",
    "        self.W3 = self.build_layer(self.ac_dim, self.h_dim, self.w3)\n",
    "        \n",
    "    def evaluate(self, X):        \n",
    "        z1 = np.tanh(np.dot(self.W1, X) + self.b1)\n",
    "        z2 = np.tanh(np.dot(self.W2, z1) + self.b2)\n",
    "        return(np.tanh(np.dot(self.W3, z2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can introduce a worker. This is similar to the code from ARS ([4] and here: https://github.com/modestyachts/ARS/blob/master/code/ars.py) so it can work with a library such as ray for parallelization. We do not include this because we have designed our experiment to work on a single machine. That being said, we leave the code in this structure in the hope it should be straightforward to scale up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class worker(object):\n",
    "    \n",
    "    def __init__(self, params, master, A, i, train=True):\n",
    "        \n",
    "        self.env = gym.make(params['env_name'])        \n",
    "        self.v = A[i, :] # the perturbation we will use\n",
    "        \n",
    "        params['zeros'] = True # initialize policy with zeros so we can set it to the current policy\n",
    "        self.policy = ToeplitzPolicy(params)        \n",
    "        self.policy.update(master.params)\n",
    "        self.timesteps = 0\n",
    "            \n",
    "    def do_rollouts(self, seed=0, train=True):\n",
    "        \n",
    "        self.policy.update(self.v) # Add the perturbation, to calculate F(theta + sigma * epsilon)\n",
    "        up, up_data = self.rollout(seed, train)\n",
    "        \n",
    "        self.policy.update(-2 * self.v) # Subtract the perturbation, to calculate F(theta - sigma * epsilon)\n",
    "        down, down_data = self.rollout(seed, train)\n",
    "        \n",
    "        self.rewards = np.reshape(np.array([up, down]), 2)\n",
    "        self.up_data = up_data\n",
    "        self.down_data = down_data\n",
    "    \n",
    "    def rollout(self, seed=0, train=True):\n",
    "        self.env.seed(0)\n",
    "        state = self.env.reset()\n",
    "        self.env._max_episode_steps = 50 # if you want to use another env, then change this!\n",
    "        total_reward = 0\n",
    "        done = False\n",
    "        data = []\n",
    "        while not done:\n",
    "            action = self.policy.evaluate(state)\n",
    "            action = np.random.multivariate_normal(action, 0.01 * np.eye(action.size), 1) # Make the policy nondeterministic\n",
    "            state, reward, done, _ = self.env.step(action)\n",
    "            total_reward += reward\n",
    "            data.append([state, reward])\n",
    "            self.timesteps += 1\n",
    "        return(total_reward, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll see that unlike usual rollouts which just return the reward, we also return all of the data from the trajectory. We will apply the Behavioral Embedding Map (BEM) to convert this data into a Probabilistic Policy Embedding (PPE). In this setting, we use the final state as the PPE, but there is potentially a lot of work that can be done on finding optimal PPEs (or learning them). In a larger scale setting you would likely want to compute multiple stochastic trajectories for a more accurate approximation of the WD, but to speed things up we just use one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed(params, data, k=100):\n",
    "    embedding = data[-1][0]\n",
    "    # add alternative PPEs\n",
    "    return(embedding)\n",
    "\n",
    "def calcdists(embeddings, dists, i, master, m_embedding, params):\n",
    "    \n",
    "    n_master = min(params['n_iter'], params['n_prev'])\n",
    "\n",
    "    if n_master== 1:\n",
    "        dists[i, 0] = master.wass.wd(m_embedding[0], embeddings[i])\n",
    "        dists[i, 1] = master.wass.wd(m_embedding[0], embeddings[i+params['num_sensings']])\n",
    "    else:\n",
    "        # if we are comparing vs multiple previous policies\n",
    "        dists[i, 0] = np.mean([master.wass.wd(x, embeddings[i]) for x in m_embedding])\n",
    "        dists[i, 1] = np.mean([master.wass.wd(x, embeddings[i+params['num_sensings']]) for x in m_embedding])\n",
    "    return(dists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The functions we introduce next are where all the calculations take place, again inspired by ARS [4] (so thanks to them...).\n",
    "\n",
    "We generate perturbations, perturb the policies (via the worker class) and then evaluate their reward and novelty (measured by WD in the PPE space). The blackbox function, Equation 6 in the paper, is: \n",
    "\n",
    "$F(\\theta) = \\mathcal{L}(\\theta) + \\beta \\mathrm{WD}_\\gamma(\\mathbb{P}_{\\pi_\\theta}^\\Phi ,\\mathbb{P}^{\\Phi}_{\\mathrm{b}})$\n",
    "\n",
    "Where $\\mathcal{L}(\\theta)$ is the cumulative undiscounted reward of the entire rollout.\n",
    "\n",
    "The gradient of this is calculated below, labelled *. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_rollouts(master, A, params):\n",
    "       \n",
    "    all_rollouts = np.zeros([params['num_sensings'], 2])\n",
    "    up, down = [],[]\n",
    "    timesteps = 0\n",
    "    \n",
    "    for i in range(params['num_sensings']):\n",
    "        w = worker(params, master, A, i)\n",
    "        w.do_rollouts()\n",
    "        all_rollouts[i] = w.rewards\n",
    "        up.append(embed(params, w.up_data))\n",
    "        down.append(embed(params, w.down_data))\n",
    "        timesteps += w.timesteps\n",
    "        \n",
    "    embeddings = up + down\n",
    "    \n",
    "    if params['optimizer'] == 'ES':\n",
    "        dists = np.zeros(params['num_sensings'])\n",
    "    else:\n",
    "        # Update behavioral test funcs and use them to calculate WDs for each perturbed policy\n",
    "        if params['n_iter'] == 1:\n",
    "            dists = np.zeros(params['num_sensings'])\n",
    "        else:\n",
    "            dists = np.zeros([params['num_sensings'], 2])\n",
    "            master.wass.update(master.buffer, embeddings, params)\n",
    "            for i in range(params['num_sensings']):\n",
    "                dists = calcdists(embeddings, dists, i, master, master.embedding, params)\n",
    "\n",
    "            # normalize dists\n",
    "            dists = (dists - np.mean(dists)) / (np.std(dists)  + 1e-8)     \n",
    "            dists = np.array(dists[:, 0] - dists[:, 1])\n",
    "        master.buffer = embeddings\n",
    "    \n",
    "    # normalize rewards    \n",
    "    all_rollouts = (all_rollouts - np.mean(all_rollouts)) / (np.std(all_rollouts)  + 1e-8)  \n",
    "    m = np.array(all_rollouts[:, 0] - all_rollouts[:, 1])\n",
    "    \n",
    "    return(m, dists, timesteps)\n",
    "\n",
    "def ES(params, master):\n",
    "    \n",
    "    A = np.random.multivariate_normal(np.zeros(master.N), np.eye(master.N), master.N)\n",
    "    A *= params['sigma']\n",
    "    A /= np.linalg.norm(A, axis =-1)[:, np.newaxis]\n",
    "        \n",
    "    m, dists, timesteps = aggregate_rollouts(master, A, params)\n",
    "\n",
    "    g = np.zeros(master.N)\n",
    "    for i in range(params['num_sensings']):\n",
    "        eps = A[i, :]\n",
    "        # combine reward and WD... beta could be adaptive as in the NSRA algorithm [3]\n",
    "        g += eps * ((1-params['beta'])*m[i] + params['beta']*dists[i]) # *\n",
    "    g /= (2 * params['sigma'])\n",
    "\n",
    "    return(g, timesteps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we have the main training procedure to initialize, update and test our agent. \n",
    "\n",
    "We include Adam here too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Adam(dx, m, v, learning_rate, t, eps = 1e-8, beta1 = 0.9, beta2 = 0.999):\n",
    "    m = beta1 * m + (1 - beta1) * dx\n",
    "    mt = m / (1 - beta1 ** t)\n",
    "    v = beta2 * v + (1-beta2) * (dx **2)\n",
    "    vt = v / (1 - beta2 ** t)\n",
    "    update = learning_rate * mt / (np.sqrt(vt) + eps)\n",
    "    return(update, m, v)\n",
    "\n",
    "def train(params):\n",
    "    \n",
    "    if params['optimizer'] == 'ES':\n",
    "        params['beta'] = 0 # ie no WD term in the blackbox function F\n",
    "    else:\n",
    "        params['beta'] = 0.5 # we use equal weight for the reward and WD. Other schemes could be tested...\n",
    "    \n",
    "    env = gym.make(params['env_name'])\n",
    "    params['ob_dim'] = env.observation_space.shape[0]\n",
    "    params['ac_dim'] = env.action_space.shape[0]\n",
    "\n",
    "    m = 0\n",
    "    v = 0\n",
    "        \n",
    "    params['zeros'] = False\n",
    "    master = ToeplitzPolicy(params)\n",
    "    params['dim'] = params['ob_dim']\n",
    "    master.wass = random_wassdist(params) # initialize the behavioral test functions\n",
    "    master.buffer = []\n",
    "    master.embedding = []\n",
    "        \n",
    "    n_iter = 1\n",
    "    ts_cumulative = 0\n",
    "    ts = []\n",
    "    rewards = []\n",
    "    all_weights = pd.DataFrame()\n",
    "    \n",
    "    while n_iter < params['max_iter']:\n",
    "            \n",
    "        params['n_iter'] = n_iter\n",
    "        \n",
    "        # main calculations\n",
    "        gradient, timesteps = ES(params, master) \n",
    "        ts_cumulative += timesteps\n",
    "        ts.append(ts_cumulative)\n",
    "        \n",
    "        # update policy\n",
    "        gradient /= (np.linalg.norm(gradient) / master.N + 1e-8)\n",
    "        update, m, v = Adam(gradient, m, v, params['learning_rate'], n_iter)\n",
    "        master.update(update)\n",
    "        \n",
    "        # evaluate new policy, keep the PPE to repel the next iteration\n",
    "        test_policy = worker(params, master, np.zeros([1, master.N]), 0)\n",
    "        reward, master_traj = test_policy.rollout()\n",
    "        master.embedding.append(embed(params, master_traj))\n",
    "        master.embedding = master.embedding[-params['n_prev']:]\n",
    "        rewards.append(reward)\n",
    "        \n",
    "        if n_iter % 10 == 0:\n",
    "            print('Iteration: %s, Reward: %s' %(n_iter, reward))\n",
    "        n_iter += 1\n",
    "        \n",
    "    df = pd.DataFrame({'Optimizer': [params['optimizer'] for _ in range(len(rewards))], 'Reward': rewards, 'Timesteps': ts})\n",
    "    return(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to specify the parameters for optimization. These are the core parameters that are shared by both ES and BGES. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}\n",
    "params['env_name'] = 'point-v0'\n",
    "params['seed'] = 0 # feel free to change this...\n",
    "params['max_iter'] = 200 # number of iterations, >100 is usually enough\n",
    "params['num_sensings'] = 50 # population size\n",
    "params['learning_rate'] = 0.1 # others should work too\n",
    "params['sigma'] = 0.1 # scale for the samples\n",
    "params['h_dim'] = 16 # size of neural network hidden layers\n",
    "params['rf_dim'] = 1000 # dimensionality of random features, higher = more accurate but slower\n",
    "params['w_iter'] = 100 # number of samples to update behavioral test funcs\n",
    "params['n_prev'] = 5 # number of previous policies to compute WD vs current. We have an ablation of this in Fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are almost ready to begin optimizing, but first, a brief comment on the environment. This is a custom environment we built to be a low dimensional problem we could use as a testbed. It is included in the paper (Fig 5.).\n",
    "\n",
    "At every timestep, the agent (a 2-d point) receives a reward linearly related to the distance from a goal. Despite the small size ($|S|=6, |A|=2$) it is non-trivial due to the deceptive barrier. This means that to solve the environment (and ultimately get a higher reward) the agent must not initially go straight, thus, it must initially opt for lower reward behaviors. The idea for this environment came from [3] who used it with a humanoid agent. \n",
    "\n",
    "Below we show the initial state of the environment. For 'qualitative' analysis, note that -775 corresponds to moving directly towards the goal and hitting the wall. This number (give or take 1-2) appears a great deal during optimization.\n",
    "\n",
    "<img src=\"point_env.png\" width=\"600\">\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can train some agents! We will do both vanilla ES and BGES. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10, Reward: -786.4071018165016\n",
      "Iteration: 20, Reward: -782.4493779827004\n",
      "Iteration: 30, Reward: -790.4627813030048\n",
      "Iteration: 40, Reward: -778.4250963978997\n",
      "Iteration: 50, Reward: -778.3073233209228\n",
      "Iteration: 60, Reward: -775.6720203170294\n",
      "Iteration: 70, Reward: -779.5878115800521\n",
      "Iteration: 80, Reward: -778.5332524376323\n",
      "Iteration: 90, Reward: -778.7424435897909\n",
      "Iteration: 100, Reward: -780.6170419413404\n",
      "Iteration: 110, Reward: -777.856131914057\n",
      "Iteration: 120, Reward: -780.3188831837132\n",
      "Iteration: 130, Reward: -778.0179316065635\n",
      "Iteration: 140, Reward: -777.2307165367548\n",
      "Iteration: 150, Reward: -777.0822951937923\n",
      "Iteration: 160, Reward: -776.6848747651477\n",
      "Iteration: 170, Reward: -779.045325314701\n",
      "Iteration: 180, Reward: -779.1847187412897\n",
      "Iteration: 190, Reward: -777.6026531218263\n"
     ]
    }
   ],
   "source": [
    "params['optimizer'] = 'ES'\n",
    "df_ES = train(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10, Reward: -810.8011621361786\n",
      "Iteration: 20, Reward: -825.5854789384737\n",
      "Iteration: 30, Reward: -729.5127980680932\n",
      "Iteration: 40, Reward: -726.412699083653\n",
      "Iteration: 50, Reward: -726.6836170303658\n",
      "Iteration: 60, Reward: -646.9842093411711\n",
      "Iteration: 70, Reward: -624.6457856998462\n",
      "Iteration: 80, Reward: -567.2963295827457\n",
      "Iteration: 90, Reward: -584.0408773453939\n",
      "Iteration: 100, Reward: -588.0199669043875\n",
      "Iteration: 110, Reward: -641.6328731531556\n",
      "Iteration: 120, Reward: -597.1871755410822\n",
      "Iteration: 130, Reward: -570.2436573145068\n",
      "Iteration: 140, Reward: -604.5276369341808\n",
      "Iteration: 150, Reward: -589.7508999403643\n",
      "Iteration: 160, Reward: -587.550520098831\n",
      "Iteration: 170, Reward: -573.2997949046613\n",
      "Iteration: 180, Reward: -568.6340457150657\n",
      "Iteration: 190, Reward: -560.8800202449662\n"
     ]
    }
   ],
   "source": [
    "params['optimizer'] = 'BGES'\n",
    "df_BGES = train(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And last but not least, we can make a simple plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x11430e278>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(df_BGES.Timesteps, df_BGES.Reward, label='BGES')\n",
    "plt.plot(df_ES.Timesteps, df_ES.Reward, label='ES')\n",
    "plt.xlabel(\"Timesteps\")\n",
    "plt.ylabel(\"Reward\")\n",
    "plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, vanilla ES gets stuck in a local optimum. BGES initially does too, but the behavioral repulsion helps it escape by being 'different' to the previous policies (which were just ending up at the wall). \n",
    "\n",
    "Of course, this is just one seed of one environment, but we hope you get the intuition behind the method. We would encourage testing other hyper-parameter settings or other seeds (the seed is most certainly not a hyper-parameter here... almost all should work)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next steps\n",
    "\n",
    "We would love to discuss potential follow up ideas/collaborations. To get things going, we propose a few:\n",
    "* Safe RL: We can use trajectories from unsafe or dangerous policies to repel from, eg a car driving dangerously\n",
    "* Multi-Agent: We can scale this approach to >1 agents, using pairwise WD\n",
    "* Adaptive $\\beta$: We can adapt the amount of emphasis placed on the novelty (WD) term, as in NSRA-ES [3], but in a more rigorous manner\n",
    "\n",
    "If you want to get in touch, please contact: behaviorguidedRL@gmail.com\n",
    "\n",
    "Thank you for your time!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### References\n",
    "\n",
    "[1] A. Rahimi and B. Recht. Random features for large-scale kernel machines. NeurIPS, 2007.\n",
    "\n",
    "[2] K. Choromanski, M. Rowland, V. Sindhwani, R. E. Turner, and A. Weller. Structured evolution\n",
    "with compact architectures for scalable policy optimization. ICML, 2018.\n",
    "\n",
    "[3] E. Conti, V. Madhavan, F. P. Such, J. Lehman, K. O. Stanley, and J. Clune. Improving exploration in evolution strategies for deep reinforcement learning via a population of novelty-seeking agents. NeurIPS, 2018.\n",
    "\n",
    "[4] H. Mania, A. Guy, and B. Recht. Simple random search provides a competitive approach to\n",
    "reinforcement learning. CoRR, 2018.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
